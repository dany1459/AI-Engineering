{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)) ])\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform )\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, (3,3), 1, (1,1))\n",
    "        self.conv2 = nn.Conv2d(8, 16, (3,3), 1, (1,1))\n",
    "        self.pool = nn.MaxPool2d((2,2), (2,2))\n",
    "        self.cf1 = nn.Linear(16*7*7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.cf1(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = Network()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 done: accuracy of 96.14, train_loss:0.00694112148287104 and test_loss: 0.008385878305119695\n",
      "1000 0 83.85878305119695 416.4672889722624 tensor(96.1400) 0\n",
      "epoch 2 done: accuracy of 96.95, train_loss:0.006874228710403652 and test_loss: 0.006922774167919124\n",
      "332.60850592106544 1 69.22774167919124 412.45372262421915 tensor(96.9500) tensor(96.1400)\n",
      "epoch 3 done: accuracy of 96.54, train_loss:0.007104952316032177 and test_loss: 0.006684733371458424\n",
      "332.60850592106544 2 66.84733371458424 426.2971389619306 tensor(96.5400) tensor(96.1400)\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "best_acc = 0\n",
    "for e in range(epochs):\n",
    "    loss_train, loss_test = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss_train+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for i, (images, labels) in enumerate(iter(testloader)):\n",
    "\n",
    "            test_output = model(images)\n",
    "            loss = criterion(test_output, labels)\n",
    "            loss_test += loss.item()\n",
    "\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            correct += (pred_y == labels).float().sum()\n",
    "            total += len(labels)\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "\n",
    "    acc = (correct/total).float()*100\n",
    "    print(f'epoch {e+1} done: accuracy of {acc:.2f}, train_loss:{loss_train/len(trainloader.dataset)} and test_loss: {loss_test/len(testloader.dataset)}')\n",
    "\n",
    "    model.train()\n",
    "    if e == 0:\n",
    "        diff_loss = 1000\n",
    "\n",
    "    if abs(loss_test-loss_train) < diff_loss + diff_loss/90 and acc > best_acc:\n",
    "        diff_loss = abs(loss_test-loss_train)\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'model_cnn_mnist.pth')\n",
    "        epoch_best = e"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6be88638bc852faf6ea9474fab08b77f1e3635d70945bf43c8983f1d48d1c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('DeepMachineLearning': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
