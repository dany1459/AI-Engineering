{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning: Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this challenge, we will be working on the credit card fraud prediction. Available to download [here](https://drive.google.com/file/d/102F1yO4uhUZ-TONJheSiXYWUgBDCoIjA/view?usp=sharing). The data is originally from [Kaggle Competition](https://www.kaggle.com/mlg-ulb/creditcardfraud)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge:** Identify fraudulent credit card transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Warning\n",
    "> There is a huge class imbalance ratio so we need to be careful when evaluating. It might be better to use method `.predict_proba()` with custom cut-off to search for fraudelent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics         import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "\n",
    "from sklearn.svm           import SVC\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\n",
    "from lightgbm              import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics        import recall_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/creditcard.csv')\n",
    "df['norm_amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df = df.drop(['Time', 'Amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "x = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESAMPLING for unbalanced systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of fraud cases\n",
    "no_of_frauds = len(df[df['Class'] == 1]) \n",
    "\n",
    "# extract indeces for fraud and non-fraud cases\n",
    "frauds_index = np.array(df[df['Class'] == 1].index)\n",
    "not_frauds_index = np.array(df[df['Class'] == 0].index)\n",
    "\n",
    "# undersampling to eliminate majority type cases\n",
    "# pick random cases of non-fraud equal to fraud cases\n",
    "random_not_frauds_index = np.random.choice(not_frauds_index, no_of_frauds, replace=False)\n",
    "\n",
    "# add together all randomly chosen fraud and non-fraud cases\n",
    "undersample_index = np.concatenate([frauds_index, random_not_frauds_index])\n",
    "\n",
    "# get values of undersampled indeces\n",
    "undersample_data = df.iloc[undersample_index, :]\n",
    "\n",
    "# split x and y again\n",
    "x_undersample = undersample_data.iloc[:, undersample_data.columns != 'Class']\n",
    "y_undersample = undersample_data.iloc[:, undersample_data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.3)\n",
    "x_train_under, x_test_under, y_train_under, y_test_under = train_test_split(x_undersample, y_undersample, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifiers = {\n",
    "  \"SVC\": SVC(),\n",
    "  \"Random Forest\": RandomForestClassifier(verbose=False),\n",
    "  \"Skl GBM\": GradientBoostingClassifier(verbose=False),\n",
    "  \"LightGBM\": LGBMClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished SVC\n",
      "Finished Random Forest\n",
      "Finished Skl GBM\n",
      "Finished LightGBM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Bal Acc.</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>98.462</td>\n",
       "      <td>93.457</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>97.856</td>\n",
       "      <td>97.228</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>96.600</td>\n",
       "      <td>96.599</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skl GBM</td>\n",
       "      <td>96.283</td>\n",
       "      <td>96.440</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Bal Acc.  Time\n",
       "0            SVC    98.462    93.457  1.92\n",
       "1  Random Forest    97.856    97.228  1.16\n",
       "2       LightGBM    96.600    96.599  0.37\n",
       "3        Skl GBM    96.283    96.440  0.89"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': [], 'Accuracy': [], 'Bal Acc.': [], 'Time': []})\n",
    "\n",
    "for model_name, model in tree_classifiers.items():\n",
    "\n",
    "        start_time = time()\n",
    "\n",
    "        model.fit(x_train_under, np.ravel(y_train_under))\n",
    "        pred = model.predict(x_test)\n",
    "\n",
    "        total_time = time() - start_time\n",
    "\n",
    "        print(f'Finished {model_name}')\n",
    "\n",
    "        results = results.append({\"Model\":    model_name,\n",
    "                                  \"Accuracy\": round(accuracy_score(y_test, pred)*100, 3),\n",
    "                                  \"Bal Acc.\": round(balanced_accuracy_score(y_test, pred)*100, 3),\n",
    "                                  \"Time\":     round(total_time, 2)}, \n",
    "                                  ignore_index=True)\n",
    "\n",
    "results_ord = pd.DataFrame(results)\n",
    "results_ord = results_ord.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.918"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc = MLPClassifier(hidden_layer_sizes=(200, ), max_iter=10000)\n",
    "mlpc.fit(x_train_under, np.ravel(y_train_under))\n",
    "mlpc_pred = mlpc.predict(x_test)\n",
    "recall_acc = round(recall_score(y_test, mlpc_pred)*100, 3)\n",
    "recall_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
