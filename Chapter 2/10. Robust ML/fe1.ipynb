{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjnuJ19dJV7v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas   1.1.4\n",
      "Sklearn  1.0.1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "import seaborn  as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn  as skl\n",
    "\n",
    "from sklearn import pipeline      # Pipeline\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram') # Useful for display the pipeline\n",
    "\n",
    "print(\"Pandas  \", pd.__version__)\n",
    "print(\"Sklearn \", skl.__version__) # Try to use 0.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset\n",
    "- **CLOUD = True**: Download dataset from Kaggle. Necesary for cloud enviroments like COLAB. **Specify your [kaggle credentials](https://www.kaggle.com/docs/api)**.\n",
    "- **CLOUD = False**: Get the dataset from your local machine. **Specify the data path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"C:\\Users\\Igor\\Documents\\GitHub\\AI-Engineering\\Chapter 2\\10. Robust ML\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAy8TnVPJV8S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame: (891, 11)\n",
      "Test DataFrame:  (418, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df      = pd.read_csv(DATA_PATH + \"\\\\train.csv\", index_col='PassengerId')\n",
    "df_test = pd.read_csv(DATA_PATH + \"\\\\test.csv\",  index_col='PassengerId')\n",
    "\n",
    "print(\"Train DataFrame:\", df.shape)\n",
    "print(\"Test DataFrame: \", df_test.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (2pts):\n",
    "Extract the title (Mr, Mrs, ... ) from the \"Name\" column.\n",
    "\n",
    "Tips:\n",
    "- split(',')[1] to get the 2nd part, and remove the surnamename\n",
    "- split('.')[0] to get the 1str part, and remove the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d56107842f0f54d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CODE HERE get_Title_from_Name funtion\n",
    "# Create this function using lambda (not def)\n",
    "\n",
    "df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "df_test['Title'] = df_test['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f3d989a17018344b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df['Title'].values[0] == \"Mr\"\n",
    "assert df['Title'].values[1] == \"Mrs\"\n",
    "assert df['Title'].values[2] == \"Miss\"\n",
    "\n",
    "assert df_test['Title'].values[0] == \"Mr\"\n",
    "assert df_test['Title'].values[1] == \"Mrs\"\n",
    "assert df_test['Title'].values[414] == \"Dona\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (1pts):\n",
    "Apply the title_dictionary to get a better information about the title. You have to overwrite the Title variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c6a842c812fafda",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Use map to apply the previous dict\n",
    "\n",
    "df[\"Title\"] = df[\"Title\"].map(title_dictionary)\n",
    "df_test[\"Title\"] = df_test[\"Title\"].map(title_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-669f5a637e57e835",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df['Title'].values[886] == \"Officer\"\n",
    "assert df_test['Title'].values[417] == \"Master\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise OPTIONAL (0pts):\n",
    "Try to extract some information from the feature **Ticket**. Search on Internet if that colum has some kind of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Ticket'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise OPTIONAL (0pts):\n",
    "Try to extract some information from the feature **Cabin**. Search on Internet if that colum has some kind of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df['Cabin'].unique()))\n",
    "print(df['Cabin'].count())\n",
    "\n",
    "df['Cabin'] = df['Cabin'].apply(lambda x: str(x)[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "For X data, notice that...\n",
    "- We drop Survived because is the target variable\n",
    "- We drop Name because we have extracted the Title: Mr, Mrs, ...\n",
    "- We drop Ticket because it has no information -> see df.Ticket.nunique()\n",
    "- We drop Cabin because it has a lot of missings (77% are missings)\n",
    "\n",
    "Then, we identify **numerical** variables and **categorical** variables,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"Survived\", 'Name', 'Ticket', 'Cabin']) # X DATA (WILL BE TRAIN+VALID DATA)\n",
    "y = df[\"Survived\"] # 0 = No, 1 = Yes\n",
    "\n",
    "x_test = df_test.drop(columns=['Name', 'Ticket', 'Cabin']) # # X_TEST DATA (NEW DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical features:\n",
      " ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']\n",
      "\n",
      "Categorical features:\n",
      " ['Sex', 'Embarked', 'Title']\n"
     ]
    }
   ],
   "source": [
    "cat_vars  = ['Sex', 'Embarked', 'Title']         # x.select_dtypes(include=[object]).columns.values.tolist()\n",
    "num_vars  = ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age'] # x.select_dtypes(exclude=[object]).columns.values.tolist()\n",
    "\n",
    "print(\"\\nNumerical features:\\n\", num_vars)\n",
    "print(\"\\nCategorical features:\\n\", cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (2pts):\n",
    "Create a **ColumnTransformer for Tree Models**. You need to create 2 pipelines (one for numerical and other for categories). Remember:\n",
    "- Categorical pipeline: Some SimpleImputer -> Some Encoder\n",
    "- Numerical pipeline: Some SimpleImputer -> NO Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c607e75fb38ea248",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "num_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='mean', add_indicator=False))\n",
    "])\n",
    "\n",
    "cat_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "    ('num', num_4_treeModels, num_vars),\n",
    "    ('cat', cat_4_treeModels, cat_vars),\n",
    "], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n",
    "\n",
    "tree_prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e636558135fb5975",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(tree_prepro)      is compose._column_transformer.ColumnTransformer\n",
    "assert type(num_4_treeModels) is pipeline.Pipeline\n",
    "assert type(cat_4_treeModels) is pipeline.Pipeline\n",
    "assert len(num_4_treeModels) == 1\n",
    "assert len(cat_4_treeModels) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (1pts):\n",
    "1. Complete the dictionary with some Tree Models.\n",
    "2. Then we put each model in a Pipeline where:\n",
    "   - first is the prepocessing with the column Transformer\n",
    "   - Then is the Tree model\n",
    "3. Display the fullpipeline of the LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree          import DecisionTreeClassifier\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.ensemble      import ExtraTreesClassifier\n",
    "from sklearn.ensemble      import AdaBoostClassifier\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\n",
    "from sklearn.experimental  import enable_hist_gradient_boosting # Necesary for HistGradientBoostingClassifier\n",
    "from sklearn.ensemble      import HistGradientBoostingClassifier\n",
    "from xgboost               import XGBClassifier\n",
    "from lightgbm              import LGBMClassifier\n",
    "from catboost              import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76a3be8223730c5a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n",
    "  \"Extra Trees\": ExtraTreesClassifier(n_estimators=300, max_depth=5),\n",
    "  \"Random Forest\": RandomForestClassifier(max_depth=5, verbose=False),\n",
    "  \"AdaBoost\": AdaBoostClassifier(),\n",
    "  \"Skl GBM\": GradientBoostingClassifier(learning_rate=0.05, verbose=False),\n",
    "  \"Skl HistGBM\": HistGradientBoostingClassifier(verbose=False),\n",
    "  \"XGBoost\": XGBClassifier(),\n",
    "  \"LightGBM\": LGBMClassifier(),\n",
    "  \"CatBoost\": CatBoostClassifier(verbose=False)\n",
    "}\n",
    "\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "tree_classifiers[\"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d4744022b37e2e9b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for pipe in tree_classifiers.values():\n",
    "    assert type(pipe) is pipeline.Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (3pts):\n",
    "Define a simple split validation strategy with:\n",
    "- 80% for train\n",
    "- 20% for validation\n",
    "- With stratification\n",
    "- random_state=0\n",
    "\n",
    "And train all the models in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "kY1uWk6-OcLw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64f17e0d448bca7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "3562463f-3197-424c-dc82-b07ad579e9cc"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "        x, y, \n",
    "        test_size=0.2, \n",
    "        random_state=0, \n",
    "        stratify=y\n",
    ")\n",
    "\n",
    "results = pd.DataFrame({'Model': [], \n",
    "                        'Accuracy': [], \n",
    "                        'Bal Acc.': [], \n",
    "                        'Time': []})\n",
    "\n",
    "for model_name, model in tree_classifiers.items():\n",
    "        start_time = time.time()\n",
    "\n",
    "        # FOR EVERY PIPELINE (PREPRO + MODEL) -> TRAIN WITH TRAIN DATA (x_train)\n",
    "        model.fit(x_train, y_train)\n",
    "        # GET PREDICTIONS USING x_val\n",
    "        pred = model.predict(x_val)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "        results = results.append({\"Model\":  model_name,\n",
    "                                \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\n",
    "                                \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\n",
    "                                \"Time\":     total_time}, \n",
    "                                ignore_index=True)\n",
    "\n",
    "results_ord = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ord = results_ord.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-af27b33fe88ad384",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert results_ord[\"Accuracy\"].min() > 75\n",
    "assert results_ord[\"Bal Acc.\"].min() > 75\n",
    "assert len(results_ord) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 (3pts):\n",
    "Define a 10 Fold cross validation strategy with:\n",
    "- With stratification\n",
    "- shuffle=True\n",
    "- random_state=0\n",
    "\n",
    "And train all the models in a for loop.\n",
    "\n",
    "Tip you can use **[cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)** for both training and predict with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-37bf16dc25b43732",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "skf = model_selection.StratifiedKFold(\n",
    "        n_splits=10,\n",
    "        random_state=0,\n",
    "        shuffle=True\n",
    ")\n",
    "\n",
    "results = pd.DataFrame({'Model': [], \n",
    "                        'Accuracy': [], \n",
    "                        'Bal Acc.': [], \n",
    "                        'Time': []})\n",
    "\n",
    "for model_name, model in tree_classifiers.items():\n",
    "        start_time = time.time()\n",
    "\n",
    "        pred = model_selection.cross_val_predict(model, x, y, cv=skf)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "        results = results.append({\"Model\":  model_name,\n",
    "                                \"Accuracy\": metrics.accuracy_score(y, pred)*100,\n",
    "                                \"Bal Acc.\": metrics.balanced_accuracy_score(y, pred)*100,\n",
    "                                \"Time\":     total_time},\n",
    "                                ignore_index=True)\n",
    "                                \n",
    "results_ord = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ord = results_ord.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-57cc085faad513cf",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert results_ord[\"Accuracy\"].min() > 75\n",
    "assert results_ord[\"Bal Acc.\"].min() > 75\n",
    "assert len(results_ord) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.1\n",
    "Train with all data the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "monuuQhHL7B_"
   },
   "outputs": [],
   "source": [
    "best_model = tree_classifiers[\"CatBoost\"]\n",
    "\n",
    "# Fit best model with all data\n",
    "\n",
    "best_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.2 (2pts)\n",
    "With your best model, generate the predicitions for test data (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44b93a0dbd4eb6fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_pred = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a29fc8d24284520e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(test_pred) == 418\n",
    "assert np.unique(test_pred).tolist() == [0,1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "colab": {
   "collapsed_sections": [],
   "name": "Titanic LogReg.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "d6e128dd2cf9bb12ecf94668e33e1546608d302a4f44df6f6afa2b8f73a532e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Strive': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "name": "seminar13_optional_practice_trees_titanic.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
