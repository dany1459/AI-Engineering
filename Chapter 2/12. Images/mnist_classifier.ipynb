{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier\n",
    "\n",
    "In this notebook you will create both, an mnist tabular dataset and a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- import the Operating System (os) module in python and any other library you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm           import SVC\n",
    "from sklearn.neighbors     import KNeighborsClassifier\n",
    "from sklearn.tree          import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble      import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble      import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.ensemble      import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.ensemble      import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble      import HistGradientBoostingClassifier\n",
    "from xgboost               import XGBClassifier, XGBRegressor\n",
    "from lightgbm              import LGBMClassifier, LGBMRegressor\n",
    "from catboost              import CatBoostClassifier, CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- As you can see each class has its own folder (Do it only for train). \n",
    "\n",
    "    - Iterate folder by folder ( os.listdir() )\n",
    "    - Inside each folder: \n",
    "        1.- Read the image\n",
    "        2.- Reshape it into a flat array (784,)\n",
    "        3.- Save the data into a pandas dataframe apending the column name as the class\n",
    "    - Save the data into a CSV\n",
    "\n",
    "    Note: if it takes to long try doing only 100 images per folder for the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the path for the folder containing all images\n",
    "path = \"C:/Users/Igor/Documents/GitHub/AI-Engineering/Chapter 2/12. Images/MNIST Digit classifier/trainingSet/\"\n",
    "directories = os.listdir(path)    # get a list of all subdirectories\n",
    "\n",
    "df1 = pd.DataFrame()    # data frame to save the tabular data\n",
    "\n",
    "for directory in list(directories):       # loop through the list of directories\n",
    "    images = os.listdir(path + directory) # get the path for all 10 image directories\n",
    "    arr = np.zeros((len(images), 785))    # create a numpy zeros array to append the values for the images later\n",
    "\n",
    "    for i, img in enumerate(images):                     # loop through each image directory\n",
    "        image = Image.open(path + directory + '/' + img) # get the path for each image\n",
    "        arr2 = np.array(image, dtype=float)              # convert the image to a numpy array\n",
    "        arr2 = arr2.flatten()                            # reshape the array into 1 dimension\n",
    "\n",
    "        arr[i,:784] = arr2          # replace the zeros array with the image data - except last column\n",
    "        arr[i,784] = int(directory) # replace last column with the labels data - 0 to 9\n",
    "\n",
    "    df2 = pd.DataFrame(data=arr) # save each iteration of the loop into a data frame\n",
    "    df = pd.concat([df1, df2])   # add that iteration to another data frame\n",
    "    df1 = df                     # final version of the data frame\n",
    "    \n",
    "df.shape\n",
    "\n",
    "# df.to_csv('C:/Users/Igor/Documents/GitHub/AI-Engineering/Chapter 2/12. Images/training_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('C:/Users/Igor/Documents/GitHub/AI-Engineering/Chapter 2/12. Images/training_set.csv')\n",
    "training_set.head()\n",
    "\n",
    "y = training_set.iloc[:,-1]\n",
    "x = training_set.iloc[:,:-1]\n",
    "\n",
    "x.shape, y.shape, training_set.iloc[:,-1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Create a dictionary of models (No preprocessing needed, it has already been done).\n",
    "    \n",
    "    Include both, tree models and mult models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeClassifier(),\n",
    "  \"Random Forest\": RandomForestClassifier(verbose=False),\n",
    "  \"CatBoost\": CatBoostClassifier(verbose=False),\n",
    "  \"kNN\": KNeighborsClassifier(),\n",
    "  \"SVC\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Using either cross validation or stratification find out which is the best model\n",
    "    - Base your code on the previous two days examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "        x, y, \n",
    "        test_size=0.2, \n",
    "        random_state=0, \n",
    "        stratify=y\n",
    ")\n",
    "\n",
    "skf = model_selection.StratifiedKFold(\n",
    "        n_splits=5,\n",
    "        random_state=0,\n",
    "        shuffle=True\n",
    ")\n",
    "\n",
    "results = pd.DataFrame({'Model': [], \n",
    "                        'Accuracy': [], \n",
    "                        'Bal Acc.': [], \n",
    "                        'Time': []})\n",
    "\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pred = model_selection.cross_val_predict(model, x, y, cv=skf)\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    print(f'Finished {model_name}')\n",
    "\n",
    "    results = results.append({\"Model\":  model_name,\n",
    "                              \"Accuracy\": metrics.accuracy_score(y, pred)*100,\n",
    "                              \"Bal Acc.\": metrics.balanced_accuracy_score(y, pred)*100,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Decision Tree\n",
      "Finished Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "        x, y, \n",
    "        test_size=0.2, \n",
    "        random_state=0, \n",
    "        stratify=y\n",
    ")\n",
    "\n",
    "results = pd.DataFrame({'Model': [], \n",
    "                        'Accuracy': [], \n",
    "                        'Bal Acc.': [], \n",
    "                        'Time': []})\n",
    "\n",
    "for model_name, model in tree_classifiers.items():\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_val)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "        print(f'Finished {model_name}')\n",
    "        \n",
    "        results = results.append({\"Model\":  model_name,\n",
    "                                  \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\n",
    "                                  \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\n",
    "                                  \"Time\":     total_time}, \n",
    "                                  ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ord = results.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "\n",
    "print(results_ord)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6e128dd2cf9bb12ecf94668e33e1546608d302a4f44df6f6afa2b8f73a532e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Strive': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
